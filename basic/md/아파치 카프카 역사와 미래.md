
- [아파치 카프카 역사와 미래](#아파치-카프카-역사와-미래)
  - [아파치 카프카의 탄생](#아파치-카프카의-탄생)
  - [카프카가 데이터 파이프라인으로 적합한 4가지 이유](#카프카가-데이터-파이프라인으로-적합한-4가지-이유)
    - [1. 높은 처리량](#1-높은-처리량)
    - [2. 확장성](#2-확장성)
    - [3. 영속성](#3-영속성)
    - [4. 고가용성](#4-고가용성)

---

# 아파치 카프카 역사와 미래

## 아파치 카프카의 탄생

- 링크드인에서는 파편화된 데이터 수집 및 분배 아키텍처를 운영하는데 큰 어려움을 겪었다.
- 데이터를 생성하고 적재하기 위해서 데이터를 생성하는 소스 어플리케이션과, 데이터가 최종 적재되는 타깃 애플리케이션을 연결해야 한다.
- 초기 운영 시 단방향 통신을 통해 애플리케이션에서 타깃 애플리케이션으로 연동하는 소스코드를 작성했으나 이는 아키텍처가 복잡하지 않아서 운영하는데 어려움은 없었다.
- 하지만, 시간이 지날 수록 아키텍처가 거대해졌고, 소스 애플리케이션과 타깃 애플리케이션의 개수가 점점 많아지며, 데이터를 전송하는 라인이 기하급수적으로 복잡해지기 시작했다.

![](/images/2022-06-04-04-33-16.png)

이를 해결하기 위해 다양한 메시징 플랫폼과 ETL 툴을 적용하여 아키텍처를 변경하려고 노력했으나 파편화된 데이터 파이프라인의 복잡도를 낮춰주는 아키텍처가 되지는 못했다.

![](/images/2022-06-04-04-33-30.png)

-> 결국 링크드인의 데이터팀은 신규 시스템을 개발했고, 그 결과물이 바로 아파치 카프카이다.
링크드인의 내부 데이터 흐름을 개선하기 위해 개발한 카프카는 각각의 애플리케이션끼리 연결하여 데이터를 처리하는 것이 아니라, 한 곳에 모아 처리할 수 있도록 **중앙집중화** 하였다.


> 메세지 큐 구조를 그대로 살린 카프카 내부 구조

![](/images/2022-06-04-04-33-46.png)

- 기존 1:1 매칭으로 개발/운영하던 데이터 파이프라인은 **커플링**으로 인해 한쪽의 이슈가 다른 한쪽의 애플리케이션에 영향을 미쳤으나, 카프카는 이러한 의존도를 없앴다.
- 이제 소스 애플리케이션에서 생성되는 데이터는 어느 타깃 애플리케이션으로 보낼 것인지 고민하지 않고 카프카로 넣으면 된다!
- 카프카 내부에 데이터가 저장되는 파티션의 동작은 FIFO 방식의 큐 자료구조와 유사하다.
- 큐에 데이터를 보내는 것이 프로듀서이고, 큐에서 데이터를 가져가는 것이 컨슈머이다.


## 카프카가 데이터 파이프라인으로 적합한 4가지 이유

### 1. 높은 처리량

- 카프카는 프로듀서가 브로커로 데이터를 보낼 때와 컨슈머가 브로커로부터 데이터를 받을 때 **모두 묶어서 전송**한다.
- 많은 양의 데이터를 송수신할 떄 맺어지는 네트워크 비용은 무시할 수 없는 규모가 된다.
- 동일한 양의 데이터를 보낼 때 네트워크 통신 횟수를 최소한으로 줄인다면 동일 시간 내에 더 많은 데이터를 전송할 수 있다.
- 많은 양의 데이터를 묶음 단위로 처리하는 배치로 빠르게 처리할 수 있기 때문에 대용량의 실시간 로그 데이터를 처리하는 데 적합하다.
- 또한 **파티션 단위**를 통해 동일 목적의 데이터를 여러 파티션에 분배하고 데이터를 병렬처리할 수 있다.
- 파티션 개수만큼 컨슈머를 늘려서 동일 시간당 데이터 처리량을 늘리는 것이다.**(스케일 아웃)**
  - 파티션 & 컨슈머를 리니어하게 늘리면서 처리량을 늘릴 수 있다.

### 2. 확장성

- 데이터 파이프라인에서 데이터를 모을 때 데이터가 얼마나 들어올 지 예측하기가 어렵다.
- 하루에 1,000건 가량 들어오는 로그 데이터라도 예상치 못한 특정 이벤트로 100만건 이상 데이터가 들어오는 경우도 있다.
- 카프카는 이러한 가변적인 환경에서 안정적으로 확장 가능하도록 설계되었다.
- 데이터가 적을 때는 카프카 클러스터의 브로커를 최소한의 개수로 운영하다가, 데이터가 많아지면 클러스터의 브로커 개수를 자연스럽게 늘려 스케일 아웃(scale-out) 할 수 있다.
- 반대로 데이터 개수가 적어지고, 추가 서버들이 더이상 필요 없어지만 브로커 개수를 줄여 스케일 인(scale-in) 할 수 있다.
- 카프카의 스케일 아웃, 스케일 인 과정은 클러스터의 무중단 운영을 지원하므로 365일 24시간 데이터를 처리해야 하는 커머스, 은행 같은 비즈니스 모델에서도 안정적인 운영이 가능해진다.

### 3. 영속성

- 영속성이란 데이터를 생성한 프로그램이 **종료되더라도 사라지지 않는 데이터의 특성**을 말한다.
- 카프카는 다른 메시징 플랫폼과 다르게 전송받은 데이터를 **메모리에 저장하지 않고, 파일 시스템에 저장한다.**
- 파일 시스템에 데이터를 적재하고 사용하는 것은 보편적으로 느리다고 생각하겠지만, 카프카는 운영체제 레벨에서 파일 시스템을 최대한 활용하는 방법으로 적용하였다.
- 운영체제에서는 파일 I/O 성능 향상을 위해 페이지 캐시(page cache) 영역을 메모리에 따로 생성하여 사용한다.
- **페이지 캐시 메모리 영역을 사용하여 한 번 읽은 파일 내용은 메모리에 저장시켰다가 다시 사용하는 방식이기 때문에 카프카가 파일 시스템에 저장하고 데이터를 저장, 전송하더라도 처리량이 높은 것이다.**
- 디스크 기반의 파일 시스템을 활용한 덕분에 브로커 애플리케이션이 장애 발생으로 인해 급작스럽게 종료되더라도 프로세스를 재시작하여 안전하게 데이터를 다시 처리할 수 있다.

### 4. 고가용성

- **3개 이상의 서버들**로 운영되는 카프카 클러스터는 일부 서버에 장애가 발생하더라도, 무중단으로 안전하고 지속적으로 데이터를 처리할 수 있다.
- 클러스터로 이루어진 카프카는 데이터의 복제(replication)를 통해 고가용성의 특징을 지니게 되었다.
- 프로듀서로 전송받은 데이터를 여러 브로커 중 1대의 브로커에만 저장하는 것이 아니라, 또 다른 브로커에도 저장하는 것이다.
- 한 브로커에 장애가 발생하더라도, 복제된 데이터가 나머지 브로커에 저장되어 있으므로 저장된 데이터를 기준으로 지속적으로 데이터 처리가 가능한 것이다.
- 이에 더하여 서버를 직접 운영하는 온프레미스(on-premise) 환경의 서버 랙 또는 퍼블릭 클라우드(public cloud)의 리전 단위 장애에도 데이터를 안전하게 복제할 수 있는 브로커 옵션들이 준비되어 있다.