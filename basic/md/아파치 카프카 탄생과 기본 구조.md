# 아파치 카프카의 탄생

- 링크드인에서는 파편화된 데이터 수집 및 분배 아키텍처를 운영하는데 큰 어려움을 겪었다.
- 데이터를 생성하고 적재하기 위해서 데이터를 생성하는 소스 어플리케이션과, 데이터가 최종 적재되는 타깃 애플리케이션을 연결해야 한다.
- 초기 운영 시 단방향 통신을 통해 애플리케이션에서 타깃 애플리케이션으로 연동하는 소스코드를 작성했으나 이는 아키텍처가 복잡하지 않아서 운영하는데 어려움은 없었다.
- 하지만, 시간이 지날 수록 아키텍처가 거대해졌고, 소스 애플리케이션과 타깃 애플리케이션의 개수가 점점 많아지며, 데이터를 전송하는 라인이 기하급수적으로 복잡해지기 시작했다.

![](/images/2022-06-04-04-33-16.png)

이를 해결하기 위해 다양한 메시징 플랫폼과 ETL 툴을 적용하여 아키텍처를 변경하려고 노력했으나 파편화된 데이터 파이프라인의 복잡도를 낮춰주는 아키텍처가 되지는 못했다.

![](/images/2022-06-04-04-33-30.png)

-> 결국 링크드인의 데이터팀은 신규 시스템을 개발했고, 그 결과물이 바로 아파치 카프카이다.
링크드인의 내부 데이터 흐름을 개선하기 위해 개발한 카프카는 각각의 애플리케이션끼리 연결하여 데이터를 처리하는 것이 아니라, 한 곳에 모아 처리할 수 있도록 **중앙집중화** 하였다.


> 메세지 큐 구조를 그대로 살린 카프카 내부 구조

![](/images/2022-06-04-04-33-46.png)

- 기존 1:1 매칭으로 개발/운영하던 데이터 파이프라인은 **커플링**으로 인해 한쪽의 이슈가 다른 한쪽의 애플리케이션에 영향을 미쳤으나, 카프카는 이러한 의존도를 없앴다.
- 이제 소스 애플리케이션에서 생성되는 데이터는 어느 타깃 애플리케이션으로 보낼 것인지 고민하지 않고 카프카로 넣으면 된다!
- 카프카 내부에 데이터가 저장되는 파티션의 동작은 FIFO 방식의 큐 자료구조와 유사하다.
- 큐에 데이터를 보내는 것이 프로듀서이고, 큐에서 데이터를 가져가는 것이 컨슈머이다.


