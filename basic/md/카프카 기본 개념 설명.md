- [카프카 기본 개념 설명](#카프카-기본-개념-설명)
  - [오픈소스 아파치 카프카 생태계](#오픈소스-아파치-카프카-생태계)
  - [카프카 브로커와 클러스터](#카프카-브로커와-클러스터)
  - [카프카 클러스터와 주키퍼](#카프카-클러스터와-주키퍼)
  - [카프카 브로커의 역할들](#카프카-브로커의-역할들)
  - [브로커 로그와 세그먼트](#브로커-로그와-세그먼트)
  - [세그먼트와 삭제 주기(cleanup.policy)](#세그먼트와-삭제-주기cleanuppolicy)
  - [복제(replication)](#복제replication)
  - [ISR(In-Sync-Replicas)](#isrin-sync-replicas)
  - [토픽과 파티션](#토픽과-파티션)
  - [레코드](#레코드)
  - [유지보수하기 좋은 토픽 이름 정하기](#유지보수하기-좋은-토픽-이름-정하기)
  - [클라이언트 메타데이터와 브로커 통신](#클라이언트-메타데이터와-브로커-통신)
  - [퀴즈](#퀴즈)

---

# 카프카 기본 개념 설명

## 오픈소스 아파치 카프카 생태계

![아파치 카프카 생태계](/images/2022-06-07-00-22-09.png)

- 토픽은 목적에 따라서 생성이 됨
- 기본적으로 데이터를 넣는 역할을 하는 것이 프로듀서
- 프로듀서가 넣은 데이터는 토픽에 데이터가 들어가게 되고, 이 토픽에 담긴 데이터를 가져가는 것이 컨슈머이다.
- 이 토픽에 저장된 데이터를 stateless, stateful 하게 데이터를 처리하고 싶다면 카프카 스트림즈라는 라이브러를 쓰면 됩니다.
- 커넥트(소스, 싱크), 스트림즈는 모두 아파치 카프카에 포함된 것입니다.
- 오픈소스 카프카에 포함된 내용들은 아파치 카프카에 기본적으로 릴리즈가 되어 있습니다. (Java로 기본적으로 제공, 공식)
- 3rd party 라이브러리 같은 경우에는 카프카에서 제공하는 기능들을 완벽히 쓰고 있다고 보장이 되지 않는다. (go, js 등으로 제공)
- 커넥트는 데이터 파이프라인을 해결하는 가장 핵심적인 툴
  - 소스 커넥터 : 프로듀서 역할, 특정 데이터 베이스나 소스 애플리케이션으로부터 데이터를 가져와서 토픽에 데이터를 넣는 역할
  - 싱크 커넥터 : 컨슈머 역할, 타겟 애플리케이션으로 보내는 역할
  - 템플릿 형태로 반복적으로 여러번 생성할 수 있음(프로듀서와 컨슈머로 구현해도 되지 않느냐? 라고 할 수 있는데 그에 대한 반박이 될 것)

cf.) Mirror maker2 : 클러스터 단위로 카프카를 운영할 때 토픽에 있는 데이터를 완벽하게 복제할 때 사용하는 것

## 카프카 브로커와 클러스터

![](/images/2022-06-07-01-30-08.png)

- 카프카 브로커는 카프카 클라이언트와 데이터를 주고 받기 위해 사용하는 주체이자, 데이터를 분산 저장하여 장애가 발생하더라도 안전하게 사용할 수 있도록 도와주는 애플리케이션.
- 카프카 2.x 버전까지는 반드시 주키퍼가 필요하고, 3.x 버전부터는 주키퍼가 필요하진 않아도 되는데, 아직까진 완벽하게 주키퍼를 대체하지 못하는 경우가 있기 때문에 아직까지는 주키퍼가 있는 카프카 클러스터를 운영하고 있다.
- 한개의 카프카 클러스터는 여러개의 브로커로 구성되어 있다.
  - 한개의 브로커는 하나의 물리 서버나, 서버, 인스턴스에서 동작하게 된다.
- 하나의 서버에는 한 개의 브로커 프로세스가 실행된다.
- 카프카 브로커 서버 1대로도 기본 기능이 실행되지만, 데이터를 안전하게 보관하고 처리하기 위해 3대 이상의 브로커 서버를 1개의 클러스터로 묶어서 운영한다.
- 카프카 클러스터로 묶은 브로커들은 프로듀서가 보낸 데이터를 안전하게 분산 저장하고 복제하는 역할을 수행한다.
- 하나의 브로커에 장애가 발생하더라도, 다른 브로커에 데이터가 복제가 되어 있으면 장애 대응에 유리하기에 데이터를 복제, 분산 저장할 때 안전한 운영을 위해 여러개의 브로커가 존재한다고 이해하면 된다.

## 카프카 클러스터와 주키퍼

![](/images/2022-06-07-01-35-38.png)

- 카프카 클러스터를 여러대로 운영하는 경우도 많습니다.
- 카프카 클러스터를 실행하기 위해서는 **주키퍼**가 필요.
- 주키퍼의 서로 다른 znode에 클러스터를 지정하면 됨
- **root znode에 각 클러스터별 znode를 생성하고, 클러스터 실행시 root가 아닌 하위 znode로 설정**
  - 고객팀, 결제팀, 주문팀이 따로 카프카 클러스터를 운영해도 주키퍼를 하나의 앙상블로 운영할 때 동시에 운영할 수 있다.
- 주키퍼의 영향도를 줄이기 위해 하나의 클러스터에 대해 주키퍼를 각각 다르게 가져갈 수도 있긴 하지만, 리소스가 많이 발생할 수 있기 때문에 위와 같이 하나의 앙상블로 관리하기도 한다.
- 주키퍼가 반드시 필요하기 때문에 위와 같이 형태를 고려했었는데 카프카 3.0 부터는 주키퍼가 없어도 클러스터 동작 가능.(아직까지는 상용에 주키퍼 없이 운영했다는 보고가 없지만, 가까운 미래에는 될 것)

## 카프카 브로커의 역할들

> **컨트롤러**

- 클러스터의 다수 브로커 중 한 대가 컨트롤러의 역할을 한다.
- **컨트롤러는 다른 브로커들의 상태를 체크하고, 브로커가 클러스터에서 빠지는 경우 해당 브로커에 존재하는 리더 파티션을 재분배 한다.**
- 카프카는 지속적으로 데이터를 처리해야 하므로, 브로커의 상태가 비정상이라면 빠르게 클러스터에서 빼내는 것이 중요하다.
- 만약 컨트롤러 역할을 하는 브로커에 장애가 생기면 다른 브로커가 컨트롤러 역할을 한다.

> **데이터 삭제**

- **카프카는** 다른 메시징 플랫폼과 다르게 **컨슈머가 데이터를 가져가더라도 토픽의 데이터는 삭제되지 않는다.**
- 또한 컨슈머나 프로듀서가 데이터 삭제를 요청할 수도 없다. **오직 브로커만이 데이터를 삭제할 수 있다.**
- 데이터 삭제는 파일 단위로 이루어지는데, 이 단위를 **`로그 세그먼트(log segment)`** 라고 부른다.
- 브로커는 로그 세그먼트 단위로 삭제하는데, clean up policy로 특정 시간이나, 특정 용량에 따라서 데이터가 삭제되도록 수행할 수 있다.
- 또한 특수한 상황에서 `compact`라는 옵션을 주게 된다면, 가장 최신의 메시지 키가 있는 레코드를 제외하고 나머지 메시지 키가 있는 레코드들을 모두 삭제하는 로직도 가능하다.
- 이 세그먼트에는 다수의 데이터가 들어 있기 때문에 일반적인 데이터베이스처럼 특정 데이터를 선별해서 삭제할 수는 없다.

> **컨슈머 오프셋 저장**

- 컨슈머 그룹은 토픽이 특정 파티션으로부터 데이터를 가져가서 처리하고 이 파티션의 어느 레코드까지 가져갔는지 확인하기 위해 오프셋을 커밋한다.
- 커밋한 오프셋은 `__consumer_offsets` 토픽에 저장합니다. (자동으로 생성되어, internal topic이라고 합니다.)
  - 컨슈머는 언젠가 장애가 발생할 수도 있고, restart 가 발생할 수도 있는데, 위에 저장된 오프셋을 바탕으로 다음 레코드를 가져가서 읽을 수 있다.
- 여기에 저장된 오프셋을 토대로 컨슈머 그룹은 다음 레코드를 가져가서 처리한다.

> **그룹 코디네이터**

- 코디네이터는 **컨슈머 그룹의 상태를 체크하고, 파티션을 컨슈머와 매칭되도록 분배하는 역할**을 한다.
- 컨슈머가 컨슈머 그룹에서 빠지면 **매칭되지 않은 파티션을 정상 동작하는 컨슈머로 할당하여 끊임없이 데이터가 처리되도록 도와준다.**
- 이렇게 **파티션을 컨슈머로 재할당하는 과정을 `리밸런스(rebalance)`** 라고 부른다.

## 브로커 로그와 세그먼트

브로커의 가장 핵심적인 역할은 데이터의 저장.

- 카프카를 실행할 때, `config/server.properties`의 `log.dir` 옵션에 정의한 디렉토리에 데이터를 저장한다. (데이터를 파일 시스템에 저장한다고 했었죠.)
- 토픽 이름과 파티션 번호의 조합으로 하위 디렉토리를 생성하여 데이터를 저장한다.
- `hello.kafka` 토픽의 0번 파티션에 존재하는 데이터를 확인할 수 있다.
- `log`에는 **메시지**와 **메타데이터**를 저장한다.
- `index`는 **메시지의 오프셋을 인덱싱한 정보를 담은 파일**이다.
- `timeindex` 파일에는 메시지에 포함된 `timestamp` 값을 기준으로 인덱싱한 정보가 담겨있다.
  - 여기서 말하는 메시지는 카프카에서는 공식적으로 레코드라고 하며, 프로듀서가 보낸 데이터를 의미한다.
  - 이 메시지에 메시지 키, 메시지 값, 타임 스탬프 값 모두 포함되어 있다.

![](/images/2022-06-07-03-39-27.png)

이러한 데이터 저장 파일은 데이터가 하나의 파일에 지속적으로 저장되는 것이 아니라, 파일시스템에서 구분되어서 저장된다.

![](/images/2022-06-07-03-42-05.png)

위와 같이 데이터 로그 파일을 나누는 기준은 다음과 같다.

- `log.segment.bytes` : 바이트 단위의 최대 세그먼트 크기 지정. 기본 값은 1GB.
- `log.roll.ms(hours)` : 세그먼트가 신규 생성된 이후 다음 파일로 넘어가는 시간 주기. 기본 값은 7일.

여기서 오프셋을 살펴보자. 오프셋은 레코드의 고유한 번호이다.
- 특정 파티션 중 하나에 데이터가 저장될 때 오프셋 0번부터 9번, 10번부터 19번까지, 20번부터 ~ 가 있고 총 22개의 레코드가 있다.
- 여기에서 프로듀서가 레코드를 전송하게 되면, active segment라고 하는 가장 최신의 세그먼트 로그에 데이터가 추가로 쓰여지게 되는 것이다. (이땐 offset=22 로 active 파일에 저장이 될 것이다.)
- **파일에 만들어지는 가장 최초의 오프셋 번호 = 파일의 이름**

- 가장 마지막 세그먼트 파일(쓰기가 일어나고 있는 파일)을 액티브 세그먼트라고 부른다.
- 액티브 세그먼트는 브로커의 삭제 대상에서 포함되지 않는다.
- 액티브 세그먼트가 아닌 세그먼트는 `retention` 옵션에 따라(시간이 지나거나, 용량에 따라) 삭제 대상으로 지정된다.

## 세그먼트와 삭제 주기(cleanup.policy)

앞서, active가 아닌 segment에 대해서 삭제가 일어난다고 했다.

> ### cleanup.policy = delete 인 경우

![](/images/2022-06-07-03-50-38.png)

- `retention.ms(minutes, hours)` : 세그먼트를 보유할 최대 기간. 기본값은 7일.
- `retention.bytes`: 파티션당 로그 적재 바이트 값. 기본 값은 -1(지정하지 않음)
- `log.retention.check.interval.ms`: 브로커가 삭제를 해야할 지 확인하는 주기. 세그먼트가 삭제 영역에 들어왔는지 확인하는 간격. 기본 값은 5분.
- 이 값이 너무 크다면, 브로커와 연동되어 있는 파일 시스템의 디스크 용량에 따라 어느 정도 데이터를 저장할 지 결정할 수 있게 된다.
- 만약 하루에 1TB가 들어오면, 7일만에 7TB가 차게 된다. 그러면, 디스크가 이 크기를 허용할 수 있을 지? 판단해야 한다.
- 즉, 디스크 용량과 토픽의 용량에 따라서 `retention.ms`, `retention.bytes`를 적절히 설정하자.
- 보통은 `retention.ms` 의 경우 3일 정도로 지정하곤 한다.

> *카프카에서 데이터는 세그먼트 단위로 삭제가 발생하기 때문에, 로그 단위(레코드 단위)로 개별 삭제는 불가능하다. 또한 로그(레코드)의 메시지 키, 메시지 값, 오프셋, 헤더 등이 이미 적재된 데이터에 대해서 수정 또한 불가능하기 때문에 데이터를 적재할 때(프로듀서) 또는 데이터를 사용할 때(컨슈머) 데이터를 검증하는 것이 좋다.*

<br/>

> ### cleanup.policy = compact 인 경우

![](/images/2022-06-07-03-59-06.png)

- 토픽 압축 정책은 일반적으로 생각하는 zip과 같은 압축(compression)과는 다른 개념이다.
- 여기서 압축이란 **메시지 `키` 별로 해당 메시지 키의 레코드 중 오래된 데이터를 삭제하는 정책**을 뜻한다.
- 그렇기 때문에 삭제(delete) 정책과 다르게 일부 레코드만 삭제가 될 수 있다.
- 압축도 액티브 세그먼트를 제외한 데이터가 대상이다.
- 스트림 데이터와 배치 데이터를 생각해보면 왜 이렇게 동작하는지 생각해볼 수 있다.
  - 가장 최신의 데이터를 활용한다는 것을 고려했을 때 key value 방식으로 최신 데이터만 추려서(out of date 된 데이터는 버리고) 데이터 처리하는 데 용이할 것이다.

> 테일/헤드 영역, 클린/더티 로그

![](/images/2022-06-07-04-28-32.png)

- 이러한 압축은 주기적으로 일어나게 되는데, 압축이 된 것과 안된 것들이 있을 수 있다. 이를 구분하기 위해 tail/head 영역으로 구분한다.
- 테일 영역 : 압축 정책에 의해 압축이 완료된 레코드들. 클린(clean) 로그 라고도 부른다. **중복 메시지 키가 없다.**
- 헤드 영역: 압축 정책이 되기 전 레코드들. 더티(dirty) 로그 라고도 부른다. 중복된 메시지 키가 있다.

> **min.cleanable.dirty.ratio**

![](/images/2022-06-07-04-31-58.png)

- 데이터의 압축 시작 시점은 `min.cleanable.dirty.ratio` 옵션 값을 따른다.
- **`min.cleanable.dirty.ratio` 옵션 값은 액티브 세그먼트를 제외한 세그먼트에 남아 있는 테일 영역의 레코드 개수와 헤드 영역의 레코드 개수의 비율을 뜻한다.**
- 예를 들어 `min.cleanable.dirty.ratio=0.5` 라고 한다면, 테일 영역의 레코드 개수가 헤드 영역의 레코드 개수가 동일할 경우 압축이 시작된다.
- `min.cleanable.dirty.ratio=0.9` 인 경우 한 번 압축을 할 때 많은 데이터가 줄어드므로 압축 효과가 좋다. 그러나 0.9 비율이 될 때까지 압축을 하지 않고 용량을 차지하므로 용량 효율은 좋지 않다.
- `min.cleanable.dirty.ratio=0.1` 과 같이 작게 설정하면 압축이 자주 일어나서 가장 최신 데이터만 유지할 수 있지만, 압축이 자주 발생하기 때문에 브로커에 부담을 줄 수 있다.

## 복제(replication)

카프카 운영에 있어서 가장 중요한 **복제**에 대해서 알아보자.

![](/images/2022-06-07-14-41-59.png)

- 데이터 복제(replication)는 카프카를 장애 허용 시스템(fault tolerant system)으로 동작하도록 하는 원동력이다.
- 복제의 이유는 **클러스터로 묶인 브로커 중 일부에 장애가 발생하더라도, 데이터를 유실하지 않고 안전하게 사용하기 위함**이다.
- **카프카의 데이터 복제는 파티션 단위로 이루어진다.**
- 토픽을 생성할 때, 파티션의 복제 개수(`replication factor`)도 같이 설정되는데, 직접 옵션을 선택하지 않으면 브로커에 설정된 옵션 값을 따라간다.
- 복제 개수의 최솟값은 1(복제 없음)이고, 최댓값은 브로커 개수만큼 설정하여 사용할 수 있다.
  - 보통 상용 환경에서는 2~3 으로 운영하는 경우가 대부분이다.
  - 위의 그림 또한 `replication factor = 3` 인 경우이다.
- 복제된 파티션은 리더(leader)와 팔로워(follower)로 구성된다.
- 프로듀서 또는 컨슈머와 직접 통신하는 파티션을 리더, 나머지 복제 데이터를 가지고 있는 파티션을 팔로워라고 부른다.
  - 그래서, 데이터가 적재 되는 것도 리더 파티션에 직접적으로 되고(이 곳에 데이터가 추가가 되고) 이 리더 파티션을 기반으로 팔로워 파티션이 따라간다라고 이해하면 된다.
- 통상적으로 리더와 팔로워라고 부르지만, 이 책에서는 파티션임을 명확히 하기 위해 파티션의 리더를 `리더 파티션`, 파티션의 팔로워를 `팔로워 파티션` 이라고 지칭한다.
- 팔로워 파티션들은 리더 파티션의 **`오프셋`** 을 확인하여, 현재 자신이 가지고 있는 오프셋과 차이가 나는 경우 리더 파티션으로부터 데이터를 가져와서 자신의 파티션에 저장하는 데, 이 과정을 `복제`라고 부른다.
- 파티션 복제로 인해, 나머지 브로커에도 파티션의 데이터가 복제되므로, **복제 개수만큼 저장 용량이 증가한다는 단점**이 있다.
  - 즉, 1GB의 데이터가 들어오고, replication factor가 3이라면, 3GB 만큼의 데이터가 저장된다는 것이지요.
- 그러나 **복제를 통해 데이터를 안전하게 사용할 수 있다는 강력한 장점때문에 카프카를 운영할 때 2 이상의 복제 개수를 정하는 것이 중요합니다.**
- 카프카 브로커가 설치된 기업용 서버는 개인용 컴퓨터와 비교가 안될 정도로 안정성이 좋으나, 서버는 해커로 인한 침입, 디스크 오류, 네트워크 연결 장애 등의 이유로 언제든 장애가 발생할 수 있다.

> ### 브로커에 장애가 발생한 경우

![](/images/2022-06-07-14-57-23.png)

- 브로커가 다운되면, 해당 브로커에 있는 리더 파티션은 사용할 수 없기 때문에 팔로워 파티션 중 하나가 리더 파티션의 지위를 넘겨받는다.(**승급**)
  - 절대로 팔로워 파티션과 네트워크 통신을 하지 않습니다.
  - 리더 파티션이 있는 브로커와 통신해서 가져옵니다.
  - 그렇기 때문에 반드시 리더 파티션이 존재해야 합니다.
- 이를 통해 데이터가 유실되지 않고, 컨슈머나 프로듀서와 데이터를 주고받도록 동작할 수 있다.
- 운영 시에는 데이터 종류마다 다른 복제 개수를 설정하고, 상황에 따라서는 토픽마다 복제 개수를 다르게 설정하여 운영하기도 한다.
- 데이터가 일부 유실되어도 무관하고, 데이터 처리 속도가 중요하다면 1 또는 2로 설정한다.
  - 메트릭의 경우에는 1로 설정하는 경우가 있다.
  - 예를 들어 만약 GPS 정보에서 처럼 매초 데이터 정보(1분에 60개)를 보낼 때 2~3개 정도는 유실되어도 상관이 없을 것입니다.
- 금융 정보와 같이 유실이 일어나면 안되는 데이터의 경우 복제 개수를 3으로 설정하기도 한다.

## ISR(In-Sync-Replicas)

## 토픽과 파티션

## 레코드

## 유지보수하기 좋은 토픽 이름 정하기

## 클라이언트 메타데이터와 브로커 통신

## 퀴즈


> 정답