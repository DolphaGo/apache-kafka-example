- [카프카 기본 개념 설명](#카프카-기본-개념-설명)
  - [오픈소스 아파치 카프카 생태계](#오픈소스-아파치-카프카-생태계)
  - [카프카 브로커와 클러스터](#카프카-브로커와-클러스터)
  - [카프카 클러스터와 주키퍼](#카프카-클러스터와-주키퍼)
  - [카프카 브로커의 역할들](#카프카-브로커의-역할들)
  - [브로커 로그와 세그먼트](#브로커-로그와-세그먼트)
  - [세그먼트와 삭제 주기(cleanup.policy)](#세그먼트와-삭제-주기cleanuppolicy)
  - [복제(replication)](#복제replication)
  - [ISR(In-Sync-Replicas)](#isrin-sync-replicas)
  - [토픽과 파티션](#토픽과-파티션)
  - [레코드](#레코드)
  - [유지보수하기 좋은 토픽 이름 정하기](#유지보수하기-좋은-토픽-이름-정하기)
  - [클라이언트 메타데이터와 브로커 통신](#클라이언트-메타데이터와-브로커-통신)
  - [퀴즈](#퀴즈)

---

# 카프카 기본 개념 설명

## 오픈소스 아파치 카프카 생태계

![아파치 카프카 생태계](/images/2022-06-07-00-22-09.png)

- 토픽은 목적에 따라서 생성이 됨
- 기본적으로 데이터를 넣는 역할을 하는 것이 프로듀서
- 프로듀서가 넣은 데이터는 토픽에 데이터가 들어가게 되고, 이 토픽에 담긴 데이터를 가져가는 것이 컨슈머이다.
- 이 토픽에 저장된 데이터를 stateless, stateful 하게 데이터를 처리하고 싶다면 카프카 스트림즈라는 라이브러를 쓰면 됩니다.
- 커넥트(소스, 싱크), 스트림즈는 모두 아파치 카프카에 포함된 것입니다.
- 오픈소스 카프카에 포함된 내용들은 아파치 카프카에 기본적으로 릴리즈가 되어 있습니다. (Java로 기본적으로 제공, 공식)
- 3rd party 라이브러리 같은 경우에는 카프카에서 제공하는 기능들을 완벽히 쓰고 있다고 보장이 되지 않는다. (go, js 등으로 제공)
- 커넥트는 데이터 파이프라인을 해결하는 가장 핵심적인 툴
  - 소스 커넥터 : 프로듀서 역할, 특정 데이터 베이스나 소스 애플리케이션으로부터 데이터를 가져와서 토픽에 데이터를 넣는 역할
  - 싱크 커넥터 : 컨슈머 역할, 타겟 애플리케이션으로 보내는 역할
  - 템플릿 형태로 반복적으로 여러번 생성할 수 있음(프로듀서와 컨슈머로 구현해도 되지 않느냐? 라고 할 수 있는데 그에 대한 반박이 될 것)

cf.) Mirror maker2 : 클러스터 단위로 카프카를 운영할 때 토픽에 있는 데이터를 완벽하게 복제할 때 사용하는 것

## 카프카 브로커와 클러스터

![](/images/2022-06-07-01-30-08.png)

- 카프카 브로커는 카프카 클라이언트와 데이터를 주고 받기 위해 사용하는 주체이자, 데이터를 분산 저장하여 장애가 발생하더라도 안전하게 사용할 수 있도록 도와주는 애플리케이션.
- 카프카 2.x 버전까지는 반드시 주키퍼가 필요하고, 3.x 버전부터는 주키퍼가 필요하진 않아도 되는데, 아직까진 완벽하게 주키퍼를 대체하지 못하는 경우가 있기 때문에 아직까지는 주키퍼가 있는 카프카 클러스터를 운영하고 있다.
- 한개의 카프카 클러스터는 여러개의 브로커로 구성되어 있다.
  - 한개의 브로커는 하나의 물리 서버나, 서버, 인스턴스에서 동작하게 된다.
- 하나의 서버에는 한 개의 브로커 프로세스가 실행된다.
- 카프카 브로커 서버 1대로도 기본 기능이 실행되지만, 데이터를 안전하게 보관하고 처리하기 위해 3대 이상의 브로커 서버를 1개의 클러스터로 묶어서 운영한다.
- 카프카 클러스터로 묶은 브로커들은 프로듀서가 보낸 데이터를 안전하게 분산 저장하고 복제하는 역할을 수행한다.
- 하나의 브로커에 장애가 발생하더라도, 다른 브로커에 데이터가 복제가 되어 있으면 장애 대응에 유리하기에 데이터를 복제, 분산 저장할 때 안전한 운영을 위해 여러개의 브로커가 존재한다고 이해하면 된다.

## 카프카 클러스터와 주키퍼

![](/images/2022-06-07-01-35-38.png)

- 카프카 클러스터를 여러대로 운영하는 경우도 많습니다.
- 카프카 클러스터를 실행하기 위해서는 **주키퍼**가 필요.
- 주키퍼의 서로 다른 znode에 클러스터를 지정하면 됨
- **root znode에 각 클러스터별 znode를 생성하고, 클러스터 실행시 root가 아닌 하위 znode로 설정**
  - 고객팀, 결제팀, 주문팀이 따로 카프카 클러스터를 운영해도 주키퍼를 하나의 앙상블로 운영할 때 동시에 운영할 수 있다.
- 주키퍼의 영향도를 줄이기 위해 하나의 클러스터에 대해 주키퍼를 각각 다르게 가져갈 수도 있긴 하지만, 리소스가 많이 발생할 수 있기 때문에 위와 같이 하나의 앙상블로 관리하기도 한다.
- 주키퍼가 반드시 필요하기 때문에 위와 같이 형태를 고려했었는데 카프카 3.0 부터는 주키퍼가 없어도 클러스터 동작 가능.(아직까지는 상용에 주키퍼 없이 운영했다는 보고가 없지만, 가까운 미래에는 될 것)

## 카프카 브로커의 역할들

> **컨트롤러**

- 클러스터의 다수 브로커 중 한 대가 컨트롤러의 역할을 한다.
- **컨트롤러는 다른 브로커들의 상태를 체크하고, 브로커가 클러스터에서 빠지는 경우 해당 브로커에 존재하는 리더 파티션을 재분배 한다.**
- 카프카는 지속적으로 데이터를 처리해야 하므로, 브로커의 상태가 비정상이라면 빠르게 클러스터에서 빼내는 것이 중요하다.
- 만약 컨트롤러 역할을 하는 브로커에 장애가 생기면 다른 브로커가 컨트롤러 역할을 한다.

> **데이터 삭제**

- **카프카는** 다른 메시징 플랫폼과 다르게 **컨슈머가 데이터를 가져가더라도 토픽의 데이터는 삭제되지 않는다.**
- 또한 컨슈머나 프로듀서가 데이터 삭제를 요청할 수도 없다. **오직 브로커만이 데이터를 삭제할 수 있다.**
- 데이터 삭제는 파일 단위로 이루어지는데, 이 단위를 **`로그 세그먼트(log segment)`** 라고 부른다.
- 브로커는 로그 세그먼트 단위로 삭제하는데, clean up policy로 특정 시간이나, 특정 용량에 따라서 데이터가 삭제되도록 수행할 수 있다.
- 또한 특수한 상황에서 `compact`라는 옵션을 주게 된다면, 가장 최신의 메시지 키가 있는 레코드를 제외하고 나머지 메시지 키가 있는 레코드들을 모두 삭제하는 로직도 가능하다.
- 이 세그먼트에는 다수의 데이터가 들어 있기 때문에 일반적인 데이터베이스처럼 특정 데이터를 선별해서 삭제할 수는 없다.

> **컨슈머 오프셋 저장**

- 컨슈머 그룹은 토픽이 특정 파티션으로부터 데이터를 가져가서 처리하고 이 파티션의 어느 레코드까지 가져갔는지 확인하기 위해 오프셋을 커밋한다.
- 커밋한 오프셋은 `__consumer_offsets` 토픽에 저장합니다. (자동으로 생성되어, internal topic이라고 합니다.)
  - 컨슈머는 언젠가 장애가 발생할 수도 있고, restart 가 발생할 수도 있는데, 위에 저장된 오프셋을 바탕으로 다음 레코드를 가져가서 읽을 수 있다.
- 여기에 저장된 오프셋을 토대로 컨슈머 그룹은 다음 레코드를 가져가서 처리한다.

> **그룹 코디네이터**

- 코디네이터는 **컨슈머 그룹의 상태를 체크하고, 파티션을 컨슈머와 매칭되도록 분배하는 역할**을 한다.
- 컨슈머가 컨슈머 그룹에서 빠지면 **매칭되지 않은 파티션을 정상 동작하는 컨슈머로 할당하여 끊임없이 데이터가 처리되도록 도와준다.**
- 이렇게 **파티션을 컨슈머로 재할당하는 과정을 `리밸런스(rebalance)`** 라고 부른다.

## 브로커 로그와 세그먼트

브로커의 가장 핵심적인 역할은 데이터의 저장.

- 카프카를 실행할 때, `config/server.properties`의 `log.dir` 옵션에 정의한 디렉토리에 데이터를 저장한다. (데이터를 파일 시스템에 저장한다고 했었죠.)
- 토픽 이름과 파티션 번호의 조합으로 하위 디렉토리를 생성하여 데이터를 저장한다.
- `hello.kafka` 토픽의 0번 파티션에 존재하는 데이터를 확인할 수 있다.
- `log`에는 **메시지**와 **메타데이터**를 저장한다.
- `index`는 **메시지의 오프셋을 인덱싱한 정보를 담은 파일**이다.
- `timeindex` 파일에는 메시지에 포함된 `timestamp` 값을 기준으로 인덱싱한 정보가 담겨있다.
  - 여기서 말하는 메시지는 카프카에서는 공식적으로 레코드라고 하며, 프로듀서가 보낸 데이터를 의미한다.
  - 이 메시지에 메시지 키, 메시지 값, 타임 스탬프 값 모두 포함되어 있다.

![](/images/2022-06-07-03-39-27.png)

이러한 데이터 저장 파일은 데이터가 하나의 파일에 지속적으로 저장되는 것이 아니라, 파일시스템에서 구분되어서 저장된다.

![](/images/2022-06-07-03-42-05.png)

위와 같이 데이터 로그 파일을 나누는 기준은 다음과 같다.

- `log.segment.bytes` : 바이트 단위의 최대 세그먼트 크기 지정. 기본 값은 1GB.
- `log.roll.ms(hours)` : 세그먼트가 신규 생성된 이후 다음 파일로 넘어가는 시간 주기. 기본 값은 7일.

여기서 오프셋을 살펴보자. 오프셋은 레코드의 고유한 번호이다.
- 특정 파티션 중 하나에 데이터가 저장될 때 오프셋 0번부터 9번, 10번부터 19번까지, 20번부터 ~ 가 있고 총 22개의 레코드가 있다.
- 여기에서 프로듀서가 레코드를 전송하게 되면, active segment라고 하는 가장 최신의 세그먼트 로그에 데이터가 추가로 쓰여지게 되는 것이다. (이땐 offset=22 로 active 파일에 저장이 될 것이다.)
- **파일에 만들어지는 가장 최초의 오프셋 번호 = 파일의 이름**

- 가장 마지막 세그먼트 파일(쓰기가 일어나고 있는 파일)을 액티브 세그먼트라고 부른다.
- 액티브 세그먼트는 브로커의 삭제 대상에서 포함되지 않는다.
- 액티브 세그먼트가 아닌 세그먼트는 `retention` 옵션에 따라 삭제 대상으로 지정된다.


## 세그먼트와 삭제 주기(cleanup.policy)

## 복제(replication)

## ISR(In-Sync-Replicas)

## 토픽과 파티션

## 레코드

## 유지보수하기 좋은 토픽 이름 정하기

## 클라이언트 메타데이터와 브로커 통신

## 퀴즈


> 정답